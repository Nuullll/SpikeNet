[Input]

# image size
image_width = 28

image_height = 28

# duration per stimuli (ms)
duration_per_training_image = 500

duration_per_testing_image = 500

# pattern & background firing rate (Hz)
pattern_firing_rate = 5
background_firing_rate = 0.0

# categories of MNIST dataset
start_category = 5

end_category = 5


[Network]

# simulation resolutions
dt_ms = 1.

# dt_s = dt_ms / 1000, will be inferred dynamically.

# network size
# input_neuron_number = Input[image_width] * Input[image_height], will be inferred dynamically.
output_neuron_number = 6

dt_s = 0.001


[Layer Basics]

# rest and peak potential of output node
o_rest = 0.

o_peak = 1.


[LIF Layer]

# rest membrane potential
v_rest = 0.

# rest threshold
v_th_rest = 5.

# amount of threshold adjustment each time
dv_th = 0.1

# time constant of LIF neuron, tau = R * C (ms)
tau = 2000.

# refractory period (ms)
refractory = 0

# effective membrane resistance
res = 1.

# number of winners of lateral inhibition
winners = 1

# activity tracking
# number of stimuli phases to track
track_phase = 1000

# target number of firing events per interested stimuli phase
firing_event_target = 1

# (auto generated) target number of activated phases = track_phase / output_neuron_number


[Synapse]

# positive learning rate of STDP
learn_rate_p = 1.

# scaling factor
learn_rate_p_scaling = 0.6

# learn_rate_p_eff = learn_rate_p * learn_rate_p_scaling, will be inferred dynamically.

# negative learning rate of STDP
learn_rate_m = 1.

learn_rate_m_scaling = 0.6

# learn_rate_m_eff = learn_rate_m * learn_rate_m_scaling, will be inferred dynamically.

# time constant of learning process (ms)
tau_p = 5.

tau_m = 5.

# synapse self-decaying
decay = 1.

decay_scaling = 0.2

# decay_eff = decay * decay_scaling, will be inferred dynamically.

# strength limit
w_min = 1.

w_max = 5.0

# device variation
variation = 0.5

# initial weight map, available options: 'random', 'min', 'max'
init_weights = random
